{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a0d59bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install langchain-ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c05fa71",
      "metadata": {},
      "outputs": [],
      "source": [
        "!ollama --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe0af3fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ensuring ollama is running\n",
        "!ollama serve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fff4a445",
      "metadata": {},
      "outputs": [],
      "source": [
        "!ollama pull llama3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0178af8",
      "metadata": {},
      "outputs": [],
      "source": [
        "!ollama pull nomic-embed-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "85a3f7e5",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the file specified.\n"
          ]
        }
      ],
      "source": [
        "rmdir /s /q data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ffaaf3ee",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution - (c:\\users\\vibhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vibhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vibhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "baf2af1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain_ollama import OllamaLLM\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b2d2283f",
      "metadata": {},
      "outputs": [],
      "source": [
        "FILEPATH    = \"Resume.pdf\"\n",
        "LOCAL_MODEL = \"llama3.2\"\n",
        "EMBEDDING   = \"nomic-embed-text\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5f872b1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(FILEPATH)\n",
        "data = loader.load()\n",
        "#The loaded text is split into manageable chunks using RecursiveCharacterTextSplitter to facilitate efficient processing.\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500, chunk_overlap=100)\n",
        "all_splits = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "21a0ec24",
      "metadata": {},
      "outputs": [],
      "source": [
        "persist_directory = 'data'\n",
        "#Chroma vector store is generated from the split documents, utilizing Ollama embeddings for semantic representation.\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=all_splits,\n",
        "    embedding=OllamaEmbeddings(model=EMBEDDING),\n",
        "    persist_directory=persist_directory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d2dce977",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Defining Prompt Template and Memory Handling\n",
        "\n",
        "llm = OllamaLLM(base_url=\"http://localhost:11434\",\n",
        "                                  model=LOCAL_MODEL,\n",
        "                                  verbose=True,\n",
        "                                  callback_manager=CallbackManager(\n",
        "                                      [StreamingStdOutCallbackHandler()])\n",
        "                                  )\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9d83ec08",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\vibhu\\AppData\\Local\\Temp\\ipykernel_25052\\209392036.py:14: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(\n"
          ]
        }
      ],
      "source": [
        "template = \"\"\" You are a knowledgeable chatbot, here to help with questions of the user. Your tone should be professional and to-the-point.\n",
        "    \n",
        "    Context: {context}\n",
        "    History: {history}\n",
        "\n",
        "    User: {question}\n",
        "    Chatbot:\n",
        "    \"\"\"\n",
        "prompt = PromptTemplate(\n",
        "        input_variables=[\"history\", \"context\", \"question\"],\n",
        "        template=template,\n",
        "    )\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "        memory_key=\"history\",\n",
        "        return_messages=True,\n",
        "        input_key=\"question\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d8a886ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "#The RetrievalQA chain is instantiated\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type='stuff',\n",
        "            retriever=retriever,\n",
        "            verbose=True,\n",
        "            chain_type_kwargs={\n",
        "                \"verbose\": True,\n",
        "                \"prompt\": prompt,\n",
        "                \"memory\": memory,\n",
        "            }\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "98ac3ad3",
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"What is your name?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "128b07e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m You are a knowledgeable chatbot, here to help with questions of the user. Your tone should be professional and to-the-point.\n",
            "    \n",
            "    Context: Name: Vibhuti Dabas  \n",
            "Eductaion: based in Manchester, UK. She holds an MSc in Advanced Computer Science with a \n",
            "specialization in Artificial Intelligence from the University of Manchester, expected to be completed \n",
            "in September 2025. Prior to that, she completed her Bachelor of Technology in Information \n",
            "Technology from Indira Gandhi Delhi Technical University for Women, graduating with an 8.6 CGPA in \n",
            "May 2024.\n",
            "\n",
            "match user-uploaded images and videos with product names. \n",
            "During her time as a Machine Learning Intern at Merilrish in Tamil Nadu, India, from April to July \n",
            "2023, she worked on social media profile analysis using API data, applying sentiment analysis \n",
            "techniques to determine whether the extracted text carried a positive, negative, or neutral tone. \n",
            "Additionally, she interned at VLink Inc. in Gurugram, India, in June-July 2022, where she developed\n",
            "\n",
            "Previously, she worked as a Data Science Intern at CRUV Dimensions Pvt. Ltd. in Bengaluru from \n",
            "September to December 2023. There, she collaborated with food apps to capture shopping cart \n",
            "screenshots, extracting key information such as item names, customizations, and pricing to propose \n",
            "cost-effective optimizations. Additionally, she built one-shot learning models using Hugging Face to \n",
            "match user-uploaded images and videos with product names.\n",
            "\n",
            "sheets with optimized inference on single-node clusters. She also developed a voice cloning system \n",
            "using SV2TTS, which generates a digital voice representation based on short audio samples, used for \n",
            "generating natural-sounding speech from written text. Additionally, she created a Freshersâ€™ Query \n",
            "Chatbot capable of answering a wide range of university-related queries, using a combination of NLP \n",
            "and deep learning techniques with a Bi-LSTM model.\n",
            "    History: []\n",
            "\n",
            "    User: What is your name?\n",
            "    Chatbot:\n",
            "    \u001b[0m\n",
            "My name is Vibhuti Dabas.\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'query': 'What is your name?', 'result': 'My name is Vibhuti Dabas.'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_chain.invoke({\"query\": query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b6115bfd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m You are a knowledgeable chatbot, here to help with questions of the user. Your tone should be professional and to-the-point.\n",
            "    \n",
            "    Context: live motion analysis models to track movement postures during rehabilitation therapy sessions for \n",
            "individuals recovering from injuries. \n",
            "Projects: she has implemented a QandA system by text extraction from a given PDF, designing a \n",
            "data extraction pipeline using Ollama to structure hardware specifications from GivEnergy data \n",
            "sheets with optimized inference on single-node clusters. She also developed a voice cloning system\n",
            "\n",
            "and deploying machine learning models for self-checkout kiosks, incorporating YOLO-based object \n",
            "detection and MMDetection to ensure real-time product recognition. She actively interacted with \n",
            "clients, handling data generation and preprocessing for model training and testing, while also \n",
            "optimizing inference on edge devices for an improved checkout experience. \n",
            "Previously, she worked as a Data Science Intern at CRUV Dimensions Pvt. Ltd. in Bengaluru from\n",
            "\n",
            "Previously, she worked as a Data Science Intern at CRUV Dimensions Pvt. Ltd. in Bengaluru from \n",
            "September to December 2023. There, she collaborated with food apps to capture shopping cart \n",
            "screenshots, extracting key information such as item names, customizations, and pricing to propose \n",
            "cost-effective optimizations. Additionally, she built one-shot learning models using Hugging Face to \n",
            "match user-uploaded images and videos with product names.\n",
            "\n",
            "match user-uploaded images and videos with product names. \n",
            "During her time as a Machine Learning Intern at Merilrish in Tamil Nadu, India, from April to July \n",
            "2023, she worked on social media profile analysis using API data, applying sentiment analysis \n",
            "techniques to determine whether the extracted text carried a positive, negative, or neutral tone. \n",
            "Additionally, she interned at VLink Inc. in Gurugram, India, in June-July 2022, where she developed\n",
            "    History: [HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={}), AIMessage(content='My name is Vibhuti Dabas.', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "    User: What are you doing these days?\n",
            "    Chatbot:\n",
            "    \u001b[0m\n",
            "I'm doing well, thank you for asking. I've been working on various projects and tasks to improve my capabilities in the field of machine learning and data analysis. Recently, I've been assisting clients with live motion analysis models for rehabilitation therapy sessions, as well as deploying voice cloning systems for self-checkout kiosks. I'm also actively engaged in optimizing inference on edge devices for real-time product recognition and other applications.\n",
            "\n",
            "In my previous roles as a Data Science Intern at CRUV Dimensions Pvt. Ltd. and Merilrish, I worked on projects such as capturing shopping cart screenshots from food apps, social media profile analysis using API data, and developing one-shot learning models to match user-uploaded images with product names. My experience has been valuable in helping me stay up-to-date with the latest advancements in machine learning and data analysis.\n",
            "\n",
            "I'm always looking for new opportunities to learn and grow, so I appreciate your interest in knowing what I've been working on lately!\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'query': 'What are you doing these days?',\n",
              " 'result': \"I'm doing well, thank you for asking. I've been working on various projects and tasks to improve my capabilities in the field of machine learning and data analysis. Recently, I've been assisting clients with live motion analysis models for rehabilitation therapy sessions, as well as deploying voice cloning systems for self-checkout kiosks. I'm also actively engaged in optimizing inference on edge devices for real-time product recognition and other applications.\\n\\nIn my previous roles as a Data Science Intern at CRUV Dimensions Pvt. Ltd. and Merilrish, I worked on projects such as capturing shopping cart screenshots from food apps, social media profile analysis using API data, and developing one-shot learning models to match user-uploaded images with product names. My experience has been valuable in helping me stay up-to-date with the latest advancements in machine learning and data analysis.\\n\\nI'm always looking for new opportunities to learn and grow, so I appreciate your interest in knowing what I've been working on lately!\"}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_chain.invoke({\"query\": \"What are you doing these days?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "59bb04d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m You are a knowledgeable chatbot, here to help with questions of the user. Your tone should be professional and to-the-point.\n",
            "    \n",
            "    Context: Intelligence Application (AIA) journal with a study on developing a university auto-reply FAQ chatbot \n",
            "using NLP and neural networks. \n",
            "Professional Experience: She has worked as a Jr. AI Engineer at Xplorazzi Adventures Pvt. Ltd. in \n",
            "Bengaluru, India, from March to October 2024. In this role, she played a crucial role in developing \n",
            "and deploying machine learning models for self-checkout kiosks, incorporating YOLO-based object\n",
            "\n",
            "and deploying machine learning models for self-checkout kiosks, incorporating YOLO-based object \n",
            "detection and MMDetection to ensure real-time product recognition. She actively interacted with \n",
            "clients, handling data generation and preprocessing for model training and testing, while also \n",
            "optimizing inference on edge devices for an improved checkout experience. \n",
            "Previously, she worked as a Data Science Intern at CRUV Dimensions Pvt. Ltd. in Bengaluru from\n",
            "\n",
            "match user-uploaded images and videos with product names. \n",
            "During her time as a Machine Learning Intern at Merilrish in Tamil Nadu, India, from April to July \n",
            "2023, she worked on social media profile analysis using API data, applying sentiment analysis \n",
            "techniques to determine whether the extracted text carried a positive, negative, or neutral tone. \n",
            "Additionally, she interned at VLink Inc. in Gurugram, India, in June-July 2022, where she developed\n",
            "\n",
            "and deep learning techniques with a Bi-LSTM model. \n",
            "Technical expertise: spans across Machine Learning & AI, including regression, classification, deep \n",
            "learning frameworks such as TensorFlow, PyTorch, and Keras, and large language models like Hugging \n",
            "Face, Transformers, BERT, and GPT. She also has experience with multi-agent systems. In the domain \n",
            "of Data & MLOps, she is skilled in RAG, NLP tools such as SpaCy and NLTK, data handling with ELK\n",
            "    History: [HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={}), AIMessage(content='My name is Vibhuti Dabas.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What are you doing these days?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thank you for asking. I've been working on various projects and tasks to improve my capabilities in the field of machine learning and data analysis. Recently, I've been assisting clients with live motion analysis models for rehabilitation therapy sessions, as well as deploying voice cloning systems for self-checkout kiosks. I'm also actively engaged in optimizing inference on edge devices for real-time product recognition and other applications.\\n\\nIn my previous roles as a Data Science Intern at CRUV Dimensions Pvt. Ltd. and Merilrish, I worked on projects such as capturing shopping cart screenshots from food apps, social media profile analysis using API data, and developing one-shot learning models to match user-uploaded images with product names. My experience has been valuable in helping me stay up-to-date with the latest advancements in machine learning and data analysis.\\n\\nI'm always looking for new opportunities to learn and grow, so I appreciate your interest in knowing what I've been working on lately!\", additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "    User: What is your experience in AI jobs?\n",
            "    Chatbot:\n",
            "    \u001b[0m\n",
            "As a Jr. AI Engineer with 2 years of experience, I have worked on various AI-related projects and tasks across different domains. My professional experience includes:\n",
            "\n",
            "- Developing machine learning models for self-checkout kiosks at Xplorazzi Adventures Pvt. Ltd., where I incorporated YOLO-based object detection and MMDetection to ensure real-time product recognition.\n",
            "- Working as a Data Science Intern at CRUV Dimensions Pvt. Ltd. and Merilrish, where I worked on projects such as capturing shopping cart screenshots from food apps and developing one-shot learning models for user-uploaded images and videos matching with product names.\n",
            "- Completing an internship at VLink Inc., where I gained experience in deep learning techniques using a Bi-LSTM model.\n",
            "\n",
            "My technical expertise spans across Machine Learning & AI, including regression, classification, deep learning frameworks such as TensorFlow, PyTorch, and Keras, and large language models like Hugging Face, Transformers, BERT, and GPT.\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'query': 'What is your experience in AI jobs?',\n",
              " 'result': 'As a Jr. AI Engineer with 2 years of experience, I have worked on various AI-related projects and tasks across different domains. My professional experience includes:\\n\\n- Developing machine learning models for self-checkout kiosks at Xplorazzi Adventures Pvt. Ltd., where I incorporated YOLO-based object detection and MMDetection to ensure real-time product recognition.\\n- Working as a Data Science Intern at CRUV Dimensions Pvt. Ltd. and Merilrish, where I worked on projects such as capturing shopping cart screenshots from food apps and developing one-shot learning models for user-uploaded images and videos matching with product names.\\n- Completing an internship at VLink Inc., where I gained experience in deep learning techniques using a Bi-LSTM model.\\n\\nMy technical expertise spans across Machine Learning & AI, including regression, classification, deep learning frameworks such as TensorFlow, PyTorch, and Keras, and large language models like Hugging Face, Transformers, BERT, and GPT.'}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_chain.invoke({\"query\": \"What is your experience in AI jobs?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4c1581c4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m You are a knowledgeable chatbot, here to help with questions of the user. Your tone should be professional and to-the-point.\n",
            "    \n",
            "    Context: May 2024. \n",
            "Research publication paper: Her research contributions include the construction of hyperspectral \n",
            "images from RGB images using CNN, published in the Multimedia Tools and Applications journal. This \n",
            "study explored an affordable approach to converting RGB images into Hyperspectral Images (HSI), \n",
            "making medical and environmental monitoring more accessible. She also contributed to the Artificial\n",
            "\n",
            "match user-uploaded images and videos with product names. \n",
            "During her time as a Machine Learning Intern at Merilrish in Tamil Nadu, India, from April to July \n",
            "2023, she worked on social media profile analysis using API data, applying sentiment analysis \n",
            "techniques to determine whether the extracted text carried a positive, negative, or neutral tone. \n",
            "Additionally, she interned at VLink Inc. in Gurugram, India, in June-July 2022, where she developed\n",
            "\n",
            "Previously, she worked as a Data Science Intern at CRUV Dimensions Pvt. Ltd. in Bengaluru from \n",
            "September to December 2023. There, she collaborated with food apps to capture shopping cart \n",
            "screenshots, extracting key information such as item names, customizations, and pricing to propose \n",
            "cost-effective optimizations. Additionally, she built one-shot learning models using Hugging Face to \n",
            "match user-uploaded images and videos with product names.\n",
            "\n",
            "live motion analysis models to track movement postures during rehabilitation therapy sessions for \n",
            "individuals recovering from injuries. \n",
            "Projects: she has implemented a QandA system by text extraction from a given PDF, designing a \n",
            "data extraction pipeline using Ollama to structure hardware specifications from GivEnergy data \n",
            "sheets with optimized inference on single-node clusters. She also developed a voice cloning system\n",
            "    History: [HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={}), AIMessage(content='My name is Vibhuti Dabas.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What are you doing these days?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thank you for asking. I've been working on various projects and tasks to improve my capabilities in the field of machine learning and data analysis. Recently, I've been assisting clients with live motion analysis models for rehabilitation therapy sessions, as well as deploying voice cloning systems for self-checkout kiosks. I'm also actively engaged in optimizing inference on edge devices for real-time product recognition and other applications.\\n\\nIn my previous roles as a Data Science Intern at CRUV Dimensions Pvt. Ltd. and Merilrish, I worked on projects such as capturing shopping cart screenshots from food apps, social media profile analysis using API data, and developing one-shot learning models to match user-uploaded images with product names. My experience has been valuable in helping me stay up-to-date with the latest advancements in machine learning and data analysis.\\n\\nI'm always looking for new opportunities to learn and grow, so I appreciate your interest in knowing what I've been working on lately!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your experience in AI jobs?', additional_kwargs={}, response_metadata={}), AIMessage(content='As a Jr. AI Engineer with 2 years of experience, I have worked on various AI-related projects and tasks across different domains. My professional experience includes:\\n\\n- Developing machine learning models for self-checkout kiosks at Xplorazzi Adventures Pvt. Ltd., where I incorporated YOLO-based object detection and MMDetection to ensure real-time product recognition.\\n- Working as a Data Science Intern at CRUV Dimensions Pvt. Ltd. and Merilrish, where I worked on projects such as capturing shopping cart screenshots from food apps and developing one-shot learning models for user-uploaded images and videos matching with product names.\\n- Completing an internship at VLink Inc., where I gained experience in deep learning techniques using a Bi-LSTM model.\\n\\nMy technical expertise spans across Machine Learning & AI, including regression, classification, deep learning frameworks such as TensorFlow, PyTorch, and Keras, and large language models like Hugging Face, Transformers, BERT, and GPT.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What all have you published?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Unfortunately, the provided context does not contain any information about publications from Vibhuti Dabas. The conversation so far has focused on her professional experience, education, and current projects. If you would like to inquire about specific research or publications related to machine learning or data analysis, I'd be happy to try and assist you further.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What all research have you published?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Unfortunately, the provided context does not contain any information about publications from Vibhuti Dabas. The conversation so far has focused on her professional experience, education, and current projects. If you would like to inquire about specific research or publications related to machine learning or data analysis, I'd be happy to try and assist you further.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What are your research publications?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Unfortunately, the provided context does not contain any information about publications from Vibhuti Dabas. The conversation so far has focused on her professional experience, education, and current projects. If you would like to inquire about specific research or publications related to machine learning or data analysis, I'd be happy to try and assist you further.\", additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "    User: What are your research contributions?\n",
            "    Chatbot:\n",
            "    \u001b[0m\n",
            "Based on the provided context, Vibhuti Dabas has made a significant research contribution in constructing hyperspectral images from RGB images using Convolutional Neural Networks (CNN). This study was published in the Multimedia Tools and Applications journal and aims to provide an affordable approach to converting RGB images into Hyperspectral Images (HSI), making medical and environmental monitoring more accessible.\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'query': 'What are your research contributions?',\n",
              " 'result': 'Based on the provided context, Vibhuti Dabas has made a significant research contribution in constructing hyperspectral images from RGB images using Convolutional Neural Networks (CNN). This study was published in the Multimedia Tools and Applications journal and aims to provide an affordable approach to converting RGB images into Hyperspectral Images (HSI), making medical and environmental monitoring more accessible.'}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_chain.invoke({\"query\": \"What are your research contributions?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7410b6c8",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
